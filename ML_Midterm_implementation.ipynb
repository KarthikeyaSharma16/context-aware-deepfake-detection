{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1KdqLn4PWpHk"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-02 21:34:57.461880: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-02 21:34:58.122865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import optuna\n",
        "import matplotlib\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0r0hwXNHnSjH"
      },
      "outputs": [],
      "source": [
        "# Train data (with images)\n",
        "traindata = pd.read_csv('multimodal_train.tsv',sep='\\t')\n",
        "\n",
        "# Validation data (with images)\n",
        "validata = pd.read_csv('multimodal_validate.tsv',sep='\\t')\n",
        "\n",
        "# Test data (with  images)\n",
        "testdata = pd.read_csv('multimodal_test_public.tsv',sep='\\t')\n",
        "\n",
        "# Train data (with and without images)\n",
        "traindata_all = pd.read_csv('all_train.tsv',sep='\\t')\n",
        "\n",
        "# Validation data (with and without images)\n",
        "validata_all = pd.read_csv('all_validate.tsv',sep='\\t')\n",
        "\n",
        "# Test data (with and without images)\n",
        "testdata_all = pd.read_csv('all_test_public.tsv',sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TKIjvfs03jQj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# MULTIMODAL DATASET\n",
        "# Train data with no missing values\n",
        "train_data = traindata[traindata['clean_title'].notnull().to_numpy()]\n",
        "\n",
        "# Validation data with no missing values\n",
        "valid_data = validata[validata['clean_title'].notnull().to_numpy()]\n",
        "\n",
        "# Test data with no missing values\n",
        "test_data = testdata[testdata['clean_title'].notnull().to_numpy()]\n",
        "\n",
        "# UNIMODAL DATASET\n",
        "train_data_all = traindata_all[traindata_all['clean_title'].notnull().to_numpy()]\n",
        "\n",
        "# Validation data with no missing values\n",
        "valid_data_all = validata_all[validata_all['clean_title'].notnull().to_numpy()]\n",
        "\n",
        "# Test data with no missing values\n",
        "test_data_all = testdata_all[testdata_all['clean_title'].notnull().to_numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dmY9Qq-i3PeT"
      },
      "outputs": [],
      "source": [
        "# Get series object with the necessary columns\n",
        "\n",
        "# MULTIMODAL DATASET\n",
        "# Train data (text and labels)\n",
        "train_frame = train_data[\"clean_title\"]\n",
        "train_labels = train_data[\"6_way_label\"]\n",
        "\n",
        "# Validation data (text and labels)\n",
        "valid_frame = valid_data[\"clean_title\"]\n",
        "valid_labels = valid_data[\"6_way_label\"]\n",
        "\n",
        "# Test data (text and labels)\n",
        "test_frame = test_data[\"clean_title\"]\n",
        "test_labels = test_data[\"6_way_label\"]\n",
        "\n",
        "# UNIMODAL DATASET\n",
        "train_frame_all = train_data_all[\"clean_title\"]\n",
        "train_labels_all = train_data_all[\"6_way_label\"]\n",
        "\n",
        "# Validation data (text and labels)\n",
        "valid_frame_all = valid_data_all[\"clean_title\"]\n",
        "valid_labels_all = valid_data_all[\"6_way_label\"]\n",
        "\n",
        "# Test data (text and labels)\n",
        "test_frame_all = test_data_all[\"clean_title\"]\n",
        "test_labels_all = test_data_all[\"6_way_label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXO-3EnMwlEo"
      },
      "source": [
        "## Multi-Class Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hJTHQecpyD4p"
      },
      "outputs": [],
      "source": [
        "# Get series object with the necessary columns\n",
        "\n",
        "# Train data (text and labels)\n",
        "train_frame = train_data[\"clean_title\"]\n",
        "train_labels = train_data[\"6_way_label\"]\n",
        "\n",
        "# Validation data (text and labels)\n",
        "valid_frame = valid_data[\"clean_title\"]\n",
        "valid_labels = valid_data[\"6_way_label\"]\n",
        "\n",
        "# Test data (text and labels)\n",
        "test_frame = test_data[\"clean_title\"]\n",
        "test_labels = test_data[\"6_way_label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "N--rbmOz3sBd",
        "outputId": "14f7cf34-0b29-4ac4-e8dc-731563bb0c23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Traindata</th>\n",
              "      <th>Validata</th>\n",
              "      <th>Testdata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>True</td>\n",
              "      <td>0.393761</td>\n",
              "      <td>0.392976</td>\n",
              "      <td>0.396281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Satire</td>\n",
              "      <td>0.059363</td>\n",
              "      <td>0.059334</td>\n",
              "      <td>0.059239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False connection</td>\n",
              "      <td>0.190108</td>\n",
              "      <td>0.190034</td>\n",
              "      <td>0.190445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Imposter content</td>\n",
              "      <td>0.020894</td>\n",
              "      <td>0.020862</td>\n",
              "      <td>0.020634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Manipulated content</td>\n",
              "      <td>0.297619</td>\n",
              "      <td>0.300125</td>\n",
              "      <td>0.294543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Misleading content</td>\n",
              "      <td>0.038255</td>\n",
              "      <td>0.036669</td>\n",
              "      <td>0.038858</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Label  Traindata  Validata  Testdata\n",
              "0                 True   0.393761  0.392976  0.396281\n",
              "1               Satire   0.059363  0.059334  0.059239\n",
              "2     False connection   0.190108  0.190034  0.190445\n",
              "3     Imposter content   0.020894  0.020862  0.020634\n",
              "4  Manipulated content   0.297619  0.300125  0.294543\n",
              "5   Misleading content   0.038255  0.036669  0.038858"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = ['True','Satire','False connection','Imposter content','Manipulated content','Misleading content']\n",
        "# Train data\n",
        "train_0 = sum(train_labels == 0)/len(train_labels)\n",
        "train_1 = sum(train_labels == 1)/len(train_labels)\n",
        "train_2 = sum(train_labels == 2)/len(train_labels)\n",
        "train_3 = sum(train_labels == 3)/len(train_labels)\n",
        "train_4 = sum(train_labels == 4)/len(train_labels)\n",
        "train_5 = sum(train_labels == 5)/len(train_labels)\n",
        "# Validation data\n",
        "validation_0 = sum(valid_labels == 0)/len(valid_labels)\n",
        "validation_1 = sum(valid_labels == 1)/len(valid_labels)\n",
        "validation_2 = sum(valid_labels == 2)/len(valid_labels)\n",
        "validation_3 = sum(valid_labels == 3)/len(valid_labels)\n",
        "validation_4 = sum(valid_labels == 4)/len(valid_labels)\n",
        "validation_5 = sum(valid_labels == 5)/len(valid_labels)\n",
        "# Test data\n",
        "test_0 = sum(test_labels == 0)/len(test_labels)\n",
        "test_1 = sum(test_labels == 1)/len(test_labels)\n",
        "test_2 = sum(test_labels == 2)/len(test_labels)\n",
        "test_3 = sum(test_labels == 3)/len(test_labels)\n",
        "test_4 = sum(test_labels == 4)/len(test_labels)\n",
        "test_5 = sum(test_labels == 5)/len(test_labels)\n",
        "\n",
        "d = {\"Label\":labels, \"Traindata\": [train_0, train_1, train_2, train_3, train_4, train_5], \n",
        "                  \"Validata\": [validation_0, validation_1, validation_2, validation_3, validation_4, validation_5],\n",
        "                  \"Testdata\": [test_0, test_1, test_2, test_3, test_4, test_5]}\n",
        "\n",
        "proportion_data = pd.DataFrame(data = d)\n",
        "proportion_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6vzzBz3JPaq"
      },
      "source": [
        "## Hyperparameter tuning\n",
        "\n",
        "### Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "V5yNXhXTlTYR"
      },
      "outputs": [],
      "source": [
        "# Convert 'series' data to list\n",
        "\n",
        "## Texts ##\n",
        "\n",
        "# Train\n",
        "train_list = list(train_frame)\n",
        "# Valid\n",
        "valid_list = list(valid_frame)\n",
        "# Test\n",
        "test_list = list(test_frame)\n",
        "\n",
        "## Labels ##\n",
        "\n",
        "# Train\n",
        "train_labels_list = list(train_labels)\n",
        "# Valid\n",
        "valid_labels_list = list(valid_labels)\n",
        "# Test\n",
        "test_labels_list = list(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3pjkK699kgZ4"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(sen):\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "AQ2boRQukkYc"
      },
      "outputs": [],
      "source": [
        "# Remove puntuations and numbers and multiple spaces\n",
        "\n",
        "train_news_clean_1 = []\n",
        "valid_news_clean_1 = []\n",
        "test_news_clean_1 = []\n",
        "# Train\n",
        "for new in train_list:\n",
        "    train_news_clean_1.append(preprocess_text(new))\n",
        "# Validation\n",
        "for new in valid_list:\n",
        "    valid_news_clean_1.append(preprocess_text(new))\n",
        "# Test\n",
        "for new in test_list:\n",
        "    test_news_clean_1.append(preprocess_text(new))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Y--UH5WRzD"
      },
      "source": [
        "### Stemmed and lemmatized data\n",
        "\n",
        "#### Stemmed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StKYgxAHWM5G",
        "outputId": "01ece85a-c97e-471c-8091-3a036d8d0be1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/davendra/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/davendra/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Initialize stemmer and stop_words\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords_stem(text):\n",
        "    text = word_tokenize(text)\n",
        "    # Stop words removal\n",
        "    text = [word for word in text if word not in stop_words]\n",
        "    # Stemming\n",
        "    stemmed_text = [stemmer.stem(word) for word in text]    \n",
        "    text_done = ' '.join(stemmed_text)\n",
        "    return text_done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS0-a_lvkPET"
      },
      "source": [
        "We remove stop words and perform stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DLno9zG1kOBB"
      },
      "outputs": [],
      "source": [
        "# Train stemmed\n",
        "train_stemmed = [remove_stopwords_stem(text) for text in train_news_clean_1]\n",
        "# Validation stemmed\n",
        "valid_stemmed = [remove_stopwords_stem(text) for text in valid_news_clean_1]\n",
        "# Test stemmed\n",
        "test_stemmed = [remove_stopwords_stem(text) for text in test_news_clean_1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP39QM4JWgGQ"
      },
      "source": [
        "#### Lemmatized data\n",
        "\n",
        "Function to remove stop words and perform lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a149RPj9kBC3",
        "outputId": "c71a9315-11b2-4d40-9c72-d437e0027e6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /home/davendra/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Initialize lemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Initialize stemmer and stop_words\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords_lem(text):\n",
        "    text = word_tokenize(text)\n",
        "    # Stop words removal\n",
        "    text = [word for word in text if word not in stop_words]\n",
        "    # Lematization\n",
        "    lemmatized_text = []\n",
        "    for word in text:\n",
        "        word1 = lemmatizer.lemmatize(word, pos = \"n\")\n",
        "        word2 = lemmatizer.lemmatize(word1, pos = \"v\")\n",
        "        word3 = lemmatizer.lemmatize(word2, pos = (\"a\"))\n",
        "        lemmatized_text.append(word3) \n",
        "    text_done = ' '.join(lemmatized_text)\n",
        "    return text_done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHwGuopDopz4"
      },
      "source": [
        "We remove stop words and perform lemmatiztion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lO6dLD_eorSg"
      },
      "outputs": [],
      "source": [
        "# Train lemmatized\n",
        "train_lemmatized = [remove_stopwords_lem(text) for text in train_news_clean_1]\n",
        "# Validation lemmatized\n",
        "valid_lemmatized = [remove_stopwords_lem(text) for text in valid_news_clean_1]\n",
        "# Test lemmatized\n",
        "test_lemmatized = [remove_stopwords_lem(text) for text in test_news_clean_1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4weu3woJPax"
      },
      "source": [
        "### Stemming\n",
        "\n",
        "#### Multinomial Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0kPyt9KJPay",
        "outputId": "ba37258b-5d2c-4d7b-bc3e-f400fe6fd3ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-02 22:20:45,434] A new study created in memory with name: no-name-3bff0c8a-fd42-4b58-98c2-e387cd928596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-02 22:20:50,043] Trial 0 finished with value: 0.648663678339119 and parameters: {'n': 2, 'min_df': 6, 'sub_tf': 0}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:20:51,917] Trial 1 finished with value: 0.6272623099996629 and parameters: {'n': 1, 'min_df': 17, 'sub_tf': 1}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:20:53,836] Trial 2 finished with value: 0.6253243908193186 and parameters: {'n': 1, 'min_df': 21, 'sub_tf': 0}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:20:55,735] Trial 3 finished with value: 0.6288463482862053 and parameters: {'n': 1, 'min_df': 15, 'sub_tf': 0}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:20:57,669] Trial 4 finished with value: 0.6302618718614135 and parameters: {'n': 1, 'min_df': 12, 'sub_tf': 1}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:20:59,617] Trial 5 finished with value: 0.6232685113410401 and parameters: {'n': 1, 'min_df': 25, 'sub_tf': 1}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:01,521] Trial 6 finished with value: 0.6250042128677834 and parameters: {'n': 1, 'min_df': 22, 'sub_tf': 0}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:03,435] Trial 7 finished with value: 0.6238246098884432 and parameters: {'n': 1, 'min_df': 24, 'sub_tf': 0}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:05,316] Trial 8 finished with value: 0.6346601058272388 and parameters: {'n': 1, 'min_df': 5, 'sub_tf': 0}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:07,203] Trial 9 finished with value: 0.6341208587509689 and parameters: {'n': 1, 'min_df': 6, 'sub_tf': 0}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:11,743] Trial 10 finished with value: 0.6462876209093054 and parameters: {'n': 2, 'min_df': 9, 'sub_tf': 1}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:16,264] Trial 11 finished with value: 0.6462876209093054 and parameters: {'n': 2, 'min_df': 9, 'sub_tf': 1}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:20,683] Trial 12 finished with value: 0.6462876209093054 and parameters: {'n': 2, 'min_df': 9, 'sub_tf': 1}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:25,287] Trial 13 finished with value: 0.6462876209093054 and parameters: {'n': 2, 'min_df': 9, 'sub_tf': 1}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:29,764] Trial 14 finished with value: 0.6422601193084156 and parameters: {'n': 2, 'min_df': 12, 'sub_tf': 0}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:34,373] Trial 15 finished with value: 0.6479390650803816 and parameters: {'n': 2, 'min_df': 7, 'sub_tf': 1}. Best is trial 0 with value: 0.648663678339119.\n",
            "[I 2024-04-02 22:21:39,092] Trial 16 finished with value: 0.649759023962792 and parameters: {'n': 2, 'min_df': 5, 'sub_tf': 0}. Best is trial 16 with value: 0.649759023962792.\n",
            "[I 2024-04-02 22:21:43,601] Trial 17 finished with value: 0.6414681001651444 and parameters: {'n': 2, 'min_df': 13, 'sub_tf': 0}. Best is trial 16 with value: 0.649759023962792.\n",
            "[I 2024-04-02 22:21:48,246] Trial 18 finished with value: 0.649759023962792 and parameters: {'n': 2, 'min_df': 5, 'sub_tf': 0}. Best is trial 16 with value: 0.649759023962792.\n"
          ]
        }
      ],
      "source": [
        "class NaiveBayesOptimizer:\n",
        "    def __init__(self, train_stemmed, train_labels, valid_stemmed, valid_labels):\n",
        "        self.train_stemmed = train_stemmed\n",
        "        self.train_labels = train_labels\n",
        "        self.valid_stemmed = valid_stemmed\n",
        "        self.valid_labels = valid_labels\n",
        "\n",
        "    def create_model(self, n, sub_tf, min_df):\n",
        "        return Pipeline([\n",
        "            ('vect', CountVectorizer(ngram_range=(1, n), min_df=min_df)),\n",
        "            ('tfidf', TfidfTransformer(sublinear_tf=sub_tf)),\n",
        "            ('classifier', MultinomialNB())\n",
        "        ])\n",
        "\n",
        "    def objective(self, trial):\n",
        "        n = trial.suggest_int(\"n\", 1, 2)\n",
        "        sub_tf = trial.suggest_categorical(\"sub_tf\", [\"True\", \"False\"])\n",
        "        min_df = trial.suggest_int(\"min_df\", 5, 25)\n",
        "\n",
        "        model = self.create_model(n, sub_tf, min_df)\n",
        "        model.fit(self.train_stemmed, self.train_labels)\n",
        "        predictions = model.predict(self.valid_stemmed)\n",
        "        acc = accuracy_score(self.valid_labels, predictions)\n",
        "\n",
        "        return acc\n",
        "\n",
        "    def optimize(self, budget):\n",
        "        np.random.seed(0)\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(self.objective, n_trials=budget, show_progress_bar=False)\n",
        "        return study.best_params, study.best_value\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = NaiveBayesOptimizer(train_stemmed, train_labels_list, valid_stemmed, valid_labels_list)\n",
        "\n",
        "# Set budget\n",
        "budget = 40\n",
        "\n",
        "# Optimize hyper-parameters\n",
        "best_params, best_score = optimizer.optimize(budget)\n",
        "\n",
        "# Print results\n",
        "print(\"Best hyper-parameters: \")\n",
        "print(best_params)\n",
        "print(\"Best score: \")\n",
        "print(best_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhTpqpnqJPa0"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-2OSisaJPa1",
        "outputId": "910392e8-0fbf-4cba-e0a5-f56b7c05cfc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-02 22:03:41,874] A new study created in memory with name: no-name-64704bfc-611b-4a65-8e3a-5d600814ed2a\n",
            "[I 2024-04-02 22:03:51,184] Trial 0 finished with value: 0.6948367092447171 and parameters: {'max_iter': 404, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 18, 'sub_tf': 1}. Best is trial 0 with value: 0.6948367092447171.\n",
            "[I 2024-04-02 22:04:00,597] Trial 1 finished with value: 0.6965050048869267 and parameters: {'max_iter': 366, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 7, 'sub_tf': 0}. Best is trial 1 with value: 0.6965050048869267.\n",
            "[I 2024-04-02 22:04:09,883] Trial 2 finished with value: 0.6950220754271847 and parameters: {'max_iter': 332, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 17, 'sub_tf': 1}. Best is trial 1 with value: 0.6965050048869267.\n",
            "[I 2024-04-02 22:04:19,453] Trial 3 finished with value: 0.6963364901755923 and parameters: {'max_iter': 356, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 8, 'sub_tf': 0}. Best is trial 1 with value: 0.6965050048869267.\n",
            "[I 2024-04-02 22:04:31,864] Trial 4 finished with value: 0.7031613359846315 and parameters: {'max_iter': 348, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 2, 'min_df': 24, 'sub_tf': 1}. Best is trial 4 with value: 0.7031613359846315.\n",
            "[I 2024-04-02 22:04:42,508] Trial 5 finished with value: 0.6965218563580601 and parameters: {'max_iter': 378, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 8, 'sub_tf': 1}. Best is trial 4 with value: 0.7031613359846315.\n",
            "[I 2024-04-02 22:04:55,007] Trial 6 finished with value: 0.7090256479390651 and parameters: {'max_iter': 401, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 2, 'min_df': 6, 'sub_tf': 0}. Best is trial 6 with value: 0.7090256479390651.\n",
            "[I 2024-04-02 22:05:15,356] Trial 7 finished with value: 0.7002965858919483 and parameters: {'max_iter': 346, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 1, 'min_df': 8, 'sub_tf': 0}. Best is trial 6 with value: 0.7090256479390651.\n",
            "[I 2024-04-02 22:05:40,811] Trial 8 finished with value: 0.7066158875669846 and parameters: {'max_iter': 416, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 23, 'sub_tf': 0}. Best is trial 6 with value: 0.7090256479390651.\n",
            "[I 2024-04-02 22:05:56,645] Trial 9 finished with value: 0.6978025681642007 and parameters: {'max_iter': 381, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 1, 'min_df': 21, 'sub_tf': 1}. Best is trial 6 with value: 0.7090256479390651.\n",
            "[I 2024-04-02 22:06:30,054] Trial 10 finished with value: 0.7117387347915473 and parameters: {'max_iter': 398, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 12, 'sub_tf': 0}. Best is trial 10 with value: 0.7117387347915473.\n",
            "[I 2024-04-02 22:07:03,835] Trial 11 finished with value: 0.7117387347915473 and parameters: {'max_iter': 395, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 12, 'sub_tf': 0}. Best is trial 10 with value: 0.7117387347915473.\n",
            "[I 2024-04-02 22:07:28,860] Trial 12 finished with value: 0.711452259782279 and parameters: {'max_iter': 393, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 13, 'sub_tf': 0}. Best is trial 10 with value: 0.7117387347915473.\n",
            "[I 2024-04-02 22:08:04,016] Trial 13 finished with value: 0.7117387347915473 and parameters: {'max_iter': 420, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 12, 'sub_tf': 0}. Best is trial 10 with value: 0.7117387347915473.\n",
            "[I 2024-04-02 22:08:30,604] Trial 14 finished with value: 0.7120083583296822 and parameters: {'max_iter': 389, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 11, 'sub_tf': 0}. Best is trial 14 with value: 0.7120083583296822.\n",
            "[I 2024-04-02 22:08:57,184] Trial 15 finished with value: 0.7104917259276735 and parameters: {'max_iter': 383, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 15, 'sub_tf': 0}. Best is trial 14 with value: 0.7120083583296822.\n",
            "[I 2024-04-02 22:09:21,620] Trial 16 finished with value: 0.7128509318863537 and parameters: {'max_iter': 408, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 10, 'sub_tf': 0}. Best is trial 16 with value: 0.7128509318863537.\n",
            "[I 2024-04-02 22:09:43,042] Trial 17 finished with value: 0.7144855245862964 and parameters: {'max_iter': 411, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 0}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:10:04,342] Trial 18 finished with value: 0.7144855245862964 and parameters: {'max_iter': 408, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 0}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:10:28,312] Trial 19 finished with value: 0.7133396245492232 and parameters: {'max_iter': 411, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 6, 'sub_tf': 0}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:10:50,056] Trial 20 finished with value: 0.7144518216440295 and parameters: {'max_iter': 371, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:11:12,131] Trial 21 finished with value: 0.7144518216440295 and parameters: {'max_iter': 366, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:11:33,728] Trial 22 finished with value: 0.7144518216440295 and parameters: {'max_iter': 373, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:11:59,848] Trial 23 finished with value: 0.7130362980688214 and parameters: {'max_iter': 325, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 9, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:12:21,896] Trial 24 finished with value: 0.7144518216440295 and parameters: {'max_iter': 414, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:12:45,481] Trial 25 finished with value: 0.7141821981058947 and parameters: {'max_iter': 389, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 7, 'sub_tf': 0}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:13:09,658] Trial 26 finished with value: 0.7130025951265545 and parameters: {'max_iter': 406, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 10, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:13:33,425] Trial 27 finished with value: 0.7141821981058947 and parameters: {'max_iter': 357, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 7, 'sub_tf': 0}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:13:54,679] Trial 28 finished with value: 0.7110646759462101 and parameters: {'max_iter': 419, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 14, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:14:19,661] Trial 29 finished with value: 0.7079303023153921 and parameters: {'max_iter': 406, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 19, 'sub_tf': 0}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:14:43,444] Trial 30 finished with value: 0.7130025951265545 and parameters: {'max_iter': 341, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 10, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:15:04,876] Trial 31 finished with value: 0.7144518216440295 and parameters: {'max_iter': 366, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:15:26,384] Trial 32 finished with value: 0.7144518216440295 and parameters: {'max_iter': 359, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:15:59,107] Trial 33 finished with value: 0.7140642378079607 and parameters: {'max_iter': 374, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 7, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:16:08,349] Trial 34 finished with value: 0.6962353813487917 and parameters: {'max_iter': 364, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 6, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:16:20,668] Trial 35 finished with value: 0.7080651140844596 and parameters: {'max_iter': 350, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 2, 'min_df': 9, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:16:47,011] Trial 36 finished with value: 0.7101546965050048 and parameters: {'max_iter': 333, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 16, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:16:56,653] Trial 37 finished with value: 0.6963364901755923 and parameters: {'max_iter': 368, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 8, 'sub_tf': 0}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:17:16,906] Trial 38 finished with value: 0.713609248087358 and parameters: {'max_iter': 386, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 6, 'sub_tf': 1}. Best is trial 17 with value: 0.7144855245862964.\n",
            "[I 2024-04-02 22:17:26,373] Trial 39 finished with value: 0.6965050048869267 and parameters: {'max_iter': 399, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 7, 'sub_tf': 0}. Best is trial 17 with value: 0.7144855245862964.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyper-parameters: \n",
            "{'max_iter': 411, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 0}\n",
            "Best score: \n",
            "0.7144855245862964\n"
          ]
        }
      ],
      "source": [
        "class LogisticRegressionOptimizer:\n",
        "    def __init__(self, train_stemmed, train_labels, valid_stemmed, valid_labels):\n",
        "        self.train_stemmed = train_stemmed\n",
        "        self.train_labels = train_labels\n",
        "        self.valid_stemmed = valid_stemmed\n",
        "        self.valid_labels = valid_labels\n",
        "\n",
        "    def create_model(self, max_iter, solver, multi_class, n, min_df, sub_tf):\n",
        "        return Pipeline([\n",
        "            ('vect', CountVectorizer(ngram_range=(1, n), min_df=min_df)),\n",
        "            ('tfidf', TfidfTransformer(sublinear_tf=sub_tf)),\n",
        "            ('classifier', LogisticRegression(random_state=3, solver=solver, multi_class=multi_class, max_iter=max_iter))\n",
        "        ])\n",
        "\n",
        "    def objective(self, trial):\n",
        "        max_iter = trial.suggest_int(\"max_iter\", 320, 420)\n",
        "        solver = trial.suggest_categorical(\"solver\", [\"newton-cg\"])\n",
        "        multi_class = trial.suggest_categorical(\"multi_class\", [\"ovr\", \"multinomial\"])\n",
        "        n = trial.suggest_int(\"n\", 1, 2)\n",
        "        min_df = trial.suggest_int(\"min_df\", 5, 25)\n",
        "        sub_tf = trial.suggest_categorical(\"sub_tf\", [\"True\", \"False\"])\n",
        "\n",
        "        model = self.create_model(max_iter, solver, multi_class, n, min_df, sub_tf)\n",
        "        model.fit(self.train_stemmed, self.train_labels)\n",
        "        predictions = model.predict(self.valid_stemmed)\n",
        "        acc = accuracy_score(self.valid_labels, predictions)\n",
        "\n",
        "        return acc\n",
        "\n",
        "    def optimize(self, budget):\n",
        "        np.random.seed(0)\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(self.objective, n_trials=budget, show_progress_bar=False)\n",
        "        return study.best_params, study.best_value\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = LogisticRegressionOptimizer(train_stemmed, train_labels_list, valid_stemmed, valid_labels_list)\n",
        "\n",
        "# Set budget\n",
        "budget = 40\n",
        "\n",
        "# Optimize hyper-parameters\n",
        "best_params, best_score = optimizer.optimize(budget)\n",
        "\n",
        "# Print results\n",
        "print(\"Best hyper-parameters: \")\n",
        "print(best_params)\n",
        "print(\"Best score: \")\n",
        "print(best_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRxSoXbnJPa3"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdc4Bt5dJPa3",
        "outputId": "07c9b35e-a6f3-4643-b5a4-b54ac4bcaa3d"
      },
      "outputs": [],
      "source": [
        "class RandomForestOptimizer:\n",
        "    def __init__(self, train_stemmed, train_labels, valid_stemmed, valid_labels):\n",
        "        self.train_stemmed = train_stemmed\n",
        "        self.train_labels = train_labels\n",
        "        self.valid_stemmed = valid_stemmed\n",
        "        self.valid_labels = valid_labels\n",
        "\n",
        "    def create_model(self, n_estimators, criterion, max_depth, n, min_df, sub_tf):\n",
        "        return Pipeline([\n",
        "            ('vect', CountVectorizer(ngram_range=(1, n), min_df=min_df)),\n",
        "            ('tfidf', TfidfTransformer(sublinear_tf=sub_tf)),\n",
        "            ('classifier', RandomForestClassifier(\n",
        "                random_state=3, n_estimators=n_estimators, criterion=criterion,\n",
        "                max_depth=max_depth\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "    def objective(self, trial):\n",
        "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 300)\n",
        "        criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
        "        max_depth = trial.suggest_int(\"max_depth\", 3, 6)\n",
        "        n = trial.suggest_int(\"n\", 1, 2)\n",
        "        min_df = trial.suggest_int(\"min_df\", 5, 25)\n",
        "        sub_tf = trial.suggest_categorical(\"sub_tf\", [\"True\", \"False\"])\n",
        "\n",
        "        model = self.create_model(n_estimators, criterion, max_depth, n, min_df, sub_tf)\n",
        "        model.fit(self.train_stemmed, self.train_labels)\n",
        "        predictions = model.predict(self.valid_stemmed)\n",
        "        accuracy = accuracy_score(self.valid_labels, predictions)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    def optimize(self, budget):\n",
        "        np.random.seed(0)\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(self.objective, n_trials=budget, show_progress_bar=False)\n",
        "        return study.best_params, study.best_value\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = RandomForestOptimizer(train_stemmed, train_labels_list, valid_stemmed, valid_labels_list)\n",
        "\n",
        "# Set budget\n",
        "budget = 40\n",
        "\n",
        "# Optimize hyper-parameters\n",
        "best_params, best_score = optimizer.optimize(budget)\n",
        "\n",
        "# Print results\n",
        "print(\"Best hyper-parameters: \")\n",
        "print(best_params)\n",
        "print(\"Best score: \")\n",
        "print(best_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFK3jDbeJPa7"
      },
      "source": [
        "### Lemmatization\n",
        "\n",
        "#### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHQq6QgYJPa7",
        "outputId": "c5bfa1c9-9ec7-4545-c12d-95de4b9de7d6",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-20 10:47:58,150]\u001b[0m A new study created in memory with name: no-name-4796fa05-0079-4e15-b342-d759c4dec0b5\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:48:03,727]\u001b[0m Trial 0 finished with value: 0.6253243908193186 and parameters: {'n': 1, 'sub_tf': 'False', 'min_df': 22}. Best is trial 0 with value: 0.6253243908193186.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:48:09,156]\u001b[0m Trial 1 finished with value: 0.6284587644501365 and parameters: {'n': 1, 'sub_tf': 'True', 'min_df': 16}. Best is trial 1 with value: 0.6284587644501365.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:48:26,419]\u001b[0m Trial 2 finished with value: 0.6436250884702235 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 11}. Best is trial 2 with value: 0.6436250884702235.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:48:43,660]\u001b[0m Trial 3 finished with value: 0.6447204340938963 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 10}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:49:00,813]\u001b[0m Trial 4 finished with value: 0.6348960264231067 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 20}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:49:06,267]\u001b[0m Trial 5 finished with value: 0.6269252805769944 and parameters: {'n': 1, 'sub_tf': 'True', 'min_df': 18}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:49:11,707]\u001b[0m Trial 6 finished with value: 0.6353004617303091 and parameters: {'n': 1, 'sub_tf': 'False', 'min_df': 5}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:49:17,090]\u001b[0m Trial 7 finished with value: 0.6272960129419298 and parameters: {'n': 1, 'sub_tf': 'False', 'min_df': 17}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:49:34,166]\u001b[0m Trial 8 finished with value: 0.6310538910046847 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 25}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:49:39,599]\u001b[0m Trial 9 finished with value: 0.6253243908193186 and parameters: {'n': 1, 'sub_tf': 'False', 'min_df': 22}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:49:56,702]\u001b[0m Trial 10 finished with value: 0.6447204340938963 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 10}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:50:13,900]\u001b[0m Trial 11 finished with value: 0.6447204340938963 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 10}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:50:31,012]\u001b[0m Trial 12 finished with value: 0.6447204340938963 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 10}. Best is trial 3 with value: 0.6447204340938963.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:50:48,384]\u001b[0m Trial 13 finished with value: 0.650230865154528 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 5}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:51:05,732]\u001b[0m Trial 14 finished with value: 0.650230865154528 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 5}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:51:23,129]\u001b[0m Trial 15 finished with value: 0.650230865154528 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 5}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:51:40,603]\u001b[0m Trial 16 finished with value: 0.6481075797917158 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 7}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:51:57,742]\u001b[0m Trial 17 finished with value: 0.6410299619156752 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 13}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:52:15,088]\u001b[0m Trial 18 finished with value: 0.6481075797917158 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 7}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:52:32,477]\u001b[0m Trial 19 finished with value: 0.6481075797917158 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 7}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:52:49,733]\u001b[0m Trial 20 finished with value: 0.6401705368878703 and parameters: {'n': 2, 'sub_tf': 'False', 'min_df': 14}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:53:07,317]\u001b[0m Trial 21 finished with value: 0.650230865154528 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 5}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:53:24,305]\u001b[0m Trial 22 finished with value: 0.650230865154528 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 5}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:53:41,437]\u001b[0m Trial 23 finished with value: 0.6474166694752452 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 8}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:53:58,546]\u001b[0m Trial 24 finished with value: 0.650230865154528 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 5}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:54:15,666]\u001b[0m Trial 25 finished with value: 0.6474166694752452 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 8}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:54:32,967]\u001b[0m Trial 26 finished with value: 0.6483940548009841 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 6}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:54:50,331]\u001b[0m Trial 27 finished with value: 0.6421590104816151 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 12}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:55:07,603]\u001b[0m Trial 28 finished with value: 0.6474166694752452 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 8}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:55:24,742]\u001b[0m Trial 29 finished with value: 0.6483940548009841 and parameters: {'n': 2, 'sub_tf': 'False', 'min_df': 6}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:55:41,872]\u001b[0m Trial 30 finished with value: 0.6457989282464359 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 9}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:55:59,295]\u001b[0m Trial 31 finished with value: 0.650230865154528 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 5}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:56:16,493]\u001b[0m Trial 32 finished with value: 0.650230865154528 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 5}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:56:33,798]\u001b[0m Trial 33 finished with value: 0.6483940548009841 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 6}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:56:50,974]\u001b[0m Trial 34 finished with value: 0.6481075797917158 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 7}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:57:08,397]\u001b[0m Trial 35 finished with value: 0.650230865154528 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 5}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:57:25,459]\u001b[0m Trial 36 finished with value: 0.6457989282464359 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 9}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:57:30,970]\u001b[0m Trial 37 finished with value: 0.6346601058272388 and parameters: {'n': 1, 'sub_tf': 'True', 'min_df': 6}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:57:48,115]\u001b[0m Trial 38 finished with value: 0.6392437059755317 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 15}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:58:05,080]\u001b[0m Trial 39 finished with value: 0.6421590104816151 and parameters: {'n': 2, 'sub_tf': 'True', 'min_df': 12}. Best is trial 13 with value: 0.650230865154528.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyper-parameters: \n",
            "{'n': 2, 'sub_tf': 'True', 'min_df': 5}\n",
            "Best score: \n",
            "0.650230865154528\n"
          ]
        }
      ],
      "source": [
        "class BayesModel:\n",
        "    def __init__(self, train_lemmatized, train_labels_list, valid_lemmatized, valid_labels_list):\n",
        "        self.train_lemmatized = train_lemmatized\n",
        "        self.train_labels_list = train_labels_list\n",
        "        self.valid_lemmatized = valid_lemmatized\n",
        "        self.valid_labels_list = valid_labels_list\n",
        "\n",
        "    def create_model(self, n, sub_tf, min_df):\n",
        "        Bayes_pipe = Pipeline([\n",
        "            ('vect', CountVectorizer(ngram_range = (1, n), min_df = min_df)),\n",
        "            ('tfidf', TfidfTransformer(sublinear_tf = sub_tf)),\n",
        "            ('classifier', MultinomialNB() )\n",
        "        ])\n",
        "        return Bayes_pipe\n",
        "\n",
        "    def train_and_evaluate(self, trial):\n",
        "        # Sample values for the hyper-parameters\n",
        "        n = trial.suggest_int(\"n\", 1, 2)\n",
        "        sub_tf = trial.suggest_int(\"sub_tf\", 0, 1) == 1\n",
        "        min_df = trial.suggest_int(\"min_df\",5,25)\n",
        "\n",
        "        # Create and fit model\n",
        "        clf_Bayes = self.create_model(n, sub_tf, min_df)\n",
        "        clf_Bayes.fit(self.train_lemmatized, self.train_labels_list)\n",
        "\n",
        "        # Obtain the predictions and accuracy\n",
        "        predictions = clf_Bayes.predict(self.valid_lemmatized)\n",
        "        acc = accuracy_score(self.valid_labels_list, predictions)\n",
        "\n",
        "        return acc\n",
        "\n",
        "    def optimize(self, budget):\n",
        "        # Select budget and set seed\n",
        "        np.random.seed(0)\n",
        "\n",
        "        # Optimize hyper-parameters\n",
        "        study_Bayes = optuna.create_study(direction=\"maximize\")\n",
        "        study_Bayes.optimize(lambda trial: self.train_and_evaluate(trial), n_trials=budget, show_progress_bar=False)\n",
        "\n",
        "        # Best hyper-parameters\n",
        "        print(\"Best hyper-parameters: \")\n",
        "        print(study_Bayes.best_params)\n",
        "        # Best score\n",
        "        print(\"Best score: \")\n",
        "        print(study_Bayes.best_value)\n",
        "\n",
        "# Initialize the model\n",
        "bayes_model = BayesModel(train_lemmatized, train_labels_list, valid_lemmatized, valid_labels_list)\n",
        "\n",
        "# Optimize hyper-parameters\n",
        "bayes_model.optimize(budget=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HkuABvFJPa8"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVQ7uu1hJPa8",
        "outputId": "e8407629-0e34-4473-cfe3-a1f28723a142"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-20 10:58:40,681]\u001b[0m A new study created in memory with name: no-name-e26fe76b-6220-4817-a426-a720ba3e5d93\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 10:59:48,879]\u001b[0m Trial 0 finished with value: 0.6963027872333255 and parameters: {'max_iter': 370, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 8, 'sub_tf': 'True'}. Best is trial 0 with value: 0.6963027872333255.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:01:59,987]\u001b[0m Trial 1 finished with value: 0.6993360520373428 and parameters: {'max_iter': 329, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 1, 'min_df': 14, 'sub_tf': 'False'}. Best is trial 1 with value: 0.6993360520373428.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:04:12,043]\u001b[0m Trial 2 finished with value: 0.7006673182568838 and parameters: {'max_iter': 362, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 1, 'min_df': 5, 'sub_tf': 'False'}. Best is trial 2 with value: 0.7006673182568838.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:06:28,408]\u001b[0m Trial 3 finished with value: 0.7081156684978599 and parameters: {'max_iter': 381, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 19, 'sub_tf': 'True'}. Best is trial 3 with value: 0.7081156684978599.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:07:37,101]\u001b[0m Trial 4 finished with value: 0.6958983519261231 and parameters: {'max_iter': 364, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 7, 'sub_tf': 'True'}. Best is trial 3 with value: 0.7081156684978599.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:08:42,287]\u001b[0m Trial 5 finished with value: 0.695578173974588 and parameters: {'max_iter': 371, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 15, 'sub_tf': 'False'}. Best is trial 3 with value: 0.7081156684978599.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:10:32,577]\u001b[0m Trial 6 finished with value: 0.6971116578477301 and parameters: {'max_iter': 398, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 1, 'min_df': 25, 'sub_tf': 'False'}. Best is trial 3 with value: 0.7081156684978599.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:12:54,998]\u001b[0m Trial 7 finished with value: 0.7083178861514611 and parameters: {'max_iter': 374, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 18, 'sub_tf': 'True'}. Best is trial 7 with value: 0.7083178861514611.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:14:12,316]\u001b[0m Trial 8 finished with value: 0.703414108051633 and parameters: {'max_iter': 373, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 2, 'min_df': 25, 'sub_tf': 'False'}. Best is trial 7 with value: 0.7083178861514611.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:15:19,585]\u001b[0m Trial 9 finished with value: 0.6942132048127801 and parameters: {'max_iter': 323, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 1, 'min_df': 22, 'sub_tf': 'True'}. Best is trial 7 with value: 0.7083178861514611.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:17:43,948]\u001b[0m Trial 10 finished with value: 0.7096154494287351 and parameters: {'max_iter': 420, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 15, 'sub_tf': 'True'}. Best is trial 10 with value: 0.7096154494287351.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:20:07,770]\u001b[0m Trial 11 finished with value: 0.7096154494287351 and parameters: {'max_iter': 419, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 15, 'sub_tf': 'True'}. Best is trial 10 with value: 0.7096154494287351.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:22:31,473]\u001b[0m Trial 12 finished with value: 0.7116713289070136 and parameters: {'max_iter': 420, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 12, 'sub_tf': 'True'}. Best is trial 12 with value: 0.7116713289070136.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:24:49,019]\u001b[0m Trial 13 finished with value: 0.7127666745306865 and parameters: {'max_iter': 419, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 11, 'sub_tf': 'True'}. Best is trial 13 with value: 0.7127666745306865.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:27:08,958]\u001b[0m Trial 14 finished with value: 0.7132385157224226 and parameters: {'max_iter': 405, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 10, 'sub_tf': 'True'}. Best is trial 14 with value: 0.7132385157224226.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:29:29,934]\u001b[0m Trial 15 finished with value: 0.7132385157224226 and parameters: {'max_iter': 403, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 10, 'sub_tf': 'True'}. Best is trial 14 with value: 0.7132385157224226.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:31:50,418]\u001b[0m Trial 16 finished with value: 0.7134407333760238 and parameters: {'max_iter': 402, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 9, 'sub_tf': 'True'}. Best is trial 16 with value: 0.7134407333760238.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning:\n",
            "\n",
            "Rounding errors prevent the line search from converging\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning:\n",
            "\n",
            "The line search algorithm did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning:\n",
            "\n",
            "Line Search failed\n",
            "\n",
            "\u001b[32m[I 2021-07-20 11:34:46,006]\u001b[0m Trial 17 finished with value: 0.7139462775100266 and parameters: {'max_iter': 400, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 6, 'sub_tf': 'True'}. Best is trial 17 with value: 0.7139462775100266.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:37:20,143]\u001b[0m Trial 18 finished with value: 0.7150921775470999 and parameters: {'max_iter': 390, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:39:54,142]\u001b[0m Trial 19 finished with value: 0.7150921775470999 and parameters: {'max_iter': 387, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:42:30,312]\u001b[0m Trial 20 finished with value: 0.7150921775470999 and parameters: {'max_iter': 351, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:45:04,606]\u001b[0m Trial 21 finished with value: 0.7150921775470999 and parameters: {'max_iter': 345, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:47:39,160]\u001b[0m Trial 22 finished with value: 0.7150921775470999 and parameters: {'max_iter': 342, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:50:00,509]\u001b[0m Trial 23 finished with value: 0.7139294260388932 and parameters: {'max_iter': 340, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 7, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:52:34,669]\u001b[0m Trial 24 finished with value: 0.7150921775470999 and parameters: {'max_iter': 352, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:54:55,351]\u001b[0m Trial 25 finished with value: 0.7134744363182906 and parameters: {'max_iter': 345, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 8, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:57:17,626]\u001b[0m Trial 26 finished with value: 0.7139294260388932 and parameters: {'max_iter': 335, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 7, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 11:59:40,677]\u001b[0m Trial 27 finished with value: 0.7116713289070136 and parameters: {'max_iter': 354, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 12, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning:\n",
            "\n",
            "Rounding errors prevent the line search from converging\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning:\n",
            "\n",
            "The line search algorithm did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning:\n",
            "\n",
            "Line Search failed\n",
            "\n",
            "\u001b[32m[I 2021-07-20 12:02:38,670]\u001b[0m Trial 28 finished with value: 0.7139462775100266 and parameters: {'max_iter': 354, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 6, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:04:01,153]\u001b[0m Trial 29 finished with value: 0.7088065788143305 and parameters: {'max_iter': 322, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 2, 'min_df': 8, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:426: LineSearchWarning:\n",
            "\n",
            "Rounding errors prevent the line search from converging\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning:\n",
            "\n",
            "The line search algorithm did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning:\n",
            "\n",
            "Line Search failed\n",
            "\n",
            "\u001b[32m[I 2021-07-20 12:06:59,823]\u001b[0m Trial 30 finished with value: 0.7139462775100266 and parameters: {'max_iter': 383, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 6, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:09:33,587]\u001b[0m Trial 31 finished with value: 0.7150921775470999 and parameters: {'max_iter': 348, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:12:07,440]\u001b[0m Trial 32 finished with value: 0.7150921775470999 and parameters: {'max_iter': 331, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:14:27,084]\u001b[0m Trial 33 finished with value: 0.7134407333760238 and parameters: {'max_iter': 332, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 9, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:16:50,314]\u001b[0m Trial 34 finished with value: 0.7139294260388932 and parameters: {'max_iter': 347, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 7, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:19:27,992]\u001b[0m Trial 35 finished with value: 0.7150921775470999 and parameters: {'max_iter': 337, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'False'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:21:48,100]\u001b[0m Trial 36 finished with value: 0.7134407333760238 and parameters: {'max_iter': 361, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 9, 'sub_tf': 'False'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:23:45,848]\u001b[0m Trial 37 finished with value: 0.6984934784806713 and parameters: {'max_iter': 389, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 1, 'min_df': 17, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:25:11,700]\u001b[0m Trial 38 finished with value: 0.7094300832462674 and parameters: {'max_iter': 360, 'solver': 'newton-cg', 'multi_class': 'ovr', 'n': 2, 'min_df': 6, 'sub_tf': 'True'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 12:27:35,943]\u001b[0m Trial 39 finished with value: 0.7112331906575444 and parameters: {'max_iter': 328, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 13, 'sub_tf': 'False'}. Best is trial 18 with value: 0.7150921775470999.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyper-parameters: \n",
            "{'max_iter': 390, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'}\n",
            "Best score: \n",
            "0.7150921775470999\n"
          ]
        }
      ],
      "source": [
        "class LogisticRegressionOptimizer:\n",
        "    def __init__(self, train_lemmatized, train_labels_list, valid_lemmatized, valid_labels_list):\n",
        "        self.train_lemmatized = train_lemmatized\n",
        "        self.train_labels_list = train_labels_list\n",
        "        self.valid_lemmatized = valid_lemmatized\n",
        "        self.valid_labels_list = valid_labels_list\n",
        "\n",
        "    def create_model(self, n, min_df, sub_tf, max_iter, solver, multi_class):\n",
        "        return Pipeline([('vect', CountVectorizer(ngram_range = (1, n), min_df = min_df)),\n",
        "                        ('tfidf', TfidfTransformer(sublinear_tf = sub_tf)),\n",
        "                        ('classifier', LogisticRegression(random_state = 3,\n",
        "                                        solver = solver, multi_class = multi_class,   max_iter = max_iter ))])\n",
        "\n",
        "    def objective(self, trial):\n",
        "        max_iter = trial.suggest_int(\"max_iter\", 320, 420)\n",
        "        solver = trial.suggest_categorical(\"solver\", [\"newton-cg\"])\n",
        "        multi_class = trial.suggest_categorical(\"multi_class\",[\"ovr\", \"multinomial\"])\n",
        "        n = trial.suggest_int(\"n\", 1, 2)\n",
        "        min_df = trial.suggest_int(\"min_df\",5,25)\n",
        "        sub_tf = trial.suggest_categorical(\"sub_tf\", [\"True\", \"False\"])\n",
        "\n",
        "        clf_Logistic = self.create_model(n, min_df, sub_tf, max_iter, solver, multi_class)\n",
        "        clf_Logistic.fit(self.train_lemmatized, self.train_labels_list)\n",
        "        predictions = clf_Logistic.predict(self.valid_lemmatized)\n",
        "        acc = accuracy_score(self.valid_labels_list, predictions)\n",
        "\n",
        "        return acc\n",
        "\n",
        "    def optimize(self, budget):\n",
        "        np.random.seed(0)\n",
        "        study = optuna.create_study(direction=\"maximize\")\n",
        "        study.optimize(self.objective, n_trials=budget, show_progress_bar=False)\n",
        "        return study.best_params, study.best_value\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = LogisticRegressionOptimizer(train_lemmatized, train_labels_list, valid_lemmatized, valid_labels_list)\n",
        "\n",
        "# Set budget\n",
        "budget = 40\n",
        "\n",
        "# Optimize hyper-parameters\n",
        "best_params, best_score = optimizer.optimize(budget)\n",
        "\n",
        "# Print results\n",
        "print(\"Best hyper-parameters: \")\n",
        "print(best_params)\n",
        "print(\"Best score: \")\n",
        "print(best_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQWMdlZ0JPa9"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6BpcfNrJPa9",
        "outputId": "822b5379-61d5-4ce8-aaef-086594f532b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-20 13:44:29,932]\u001b[0m A new study created in memory with name: no-name-1de3f99b-1a25-4e07-8a7f-0a788f62457b\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:44:58,103]\u001b[0m Trial 0 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 158, 'criterion': 'gini', 'max_depth': 4, 'n': 1, 'min_df': 25, 'sub_tf': 'False'}. Best is trial 0 with value: 0.3929763068315864.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:45:38,170]\u001b[0m Trial 1 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 258, 'criterion': 'gini', 'max_depth': 4, 'n': 1, 'min_df': 10, 'sub_tf': 'True'}. Best is trial 0 with value: 0.3929763068315864.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:46:15,293]\u001b[0m Trial 2 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 110, 'criterion': 'entropy', 'max_depth': 6, 'n': 2, 'min_df': 15, 'sub_tf': 'False'}. Best is trial 0 with value: 0.3929763068315864.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:46:49,297]\u001b[0m Trial 3 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 140, 'criterion': 'gini', 'max_depth': 3, 'n': 2, 'min_df': 7, 'sub_tf': 'False'}. Best is trial 0 with value: 0.3929763068315864.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:47:09,700]\u001b[0m Trial 4 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 117, 'criterion': 'gini', 'max_depth': 3, 'n': 1, 'min_df': 16, 'sub_tf': 'True'}. Best is trial 0 with value: 0.3929763068315864.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:47:55,840]\u001b[0m Trial 5 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 255, 'criterion': 'entropy', 'max_depth': 4, 'n': 1, 'min_df': 15, 'sub_tf': 'True'}. Best is trial 0 with value: 0.3929763068315864.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:48:30,171]\u001b[0m Trial 6 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 179, 'criterion': 'entropy', 'max_depth': 4, 'n': 1, 'min_df': 24, 'sub_tf': 'False'}. Best is trial 0 with value: 0.3929763068315864.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:49:03,658]\u001b[0m Trial 7 finished with value: 0.4064237807960635 and parameters: {'n_estimators': 177, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 10, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:49:38,442]\u001b[0m Trial 8 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 140, 'criterion': 'entropy', 'max_depth': 3, 'n': 2, 'min_df': 8, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:50:23,849]\u001b[0m Trial 9 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 275, 'criterion': 'gini', 'max_depth': 5, 'n': 1, 'min_df': 9, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:51:15,635]\u001b[0m Trial 10 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 210, 'criterion': 'gini', 'max_depth': 6, 'n': 2, 'min_df': 19, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:51:50,516]\u001b[0m Trial 11 finished with value: 0.3929931583027198 and parameters: {'n_estimators': 191, 'criterion': 'gini', 'max_depth': 5, 'n': 1, 'min_df': 25, 'sub_tf': 'False'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:52:28,505]\u001b[0m Trial 12 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 216, 'criterion': 'gini', 'max_depth': 5, 'n': 1, 'min_df': 20, 'sub_tf': 'False'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:53:03,775]\u001b[0m Trial 13 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 183, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 12, 'sub_tf': 'False'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:53:40,843]\u001b[0m Trial 14 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 231, 'criterion': 'gini', 'max_depth': 5, 'n': 1, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:54:15,701]\u001b[0m Trial 15 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 183, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 12, 'sub_tf': 'False'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:54:44,948]\u001b[0m Trial 16 finished with value: 0.393077415658387 and parameters: {'n_estimators': 153, 'criterion': 'gini', 'max_depth': 5, 'n': 1, 'min_df': 22, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:55:14,621]\u001b[0m Trial 17 finished with value: 0.39306056418725355 and parameters: {'n_estimators': 158, 'criterion': 'gini', 'max_depth': 5, 'n': 1, 'min_df': 22, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:55:40,781]\u001b[0m Trial 18 finished with value: 0.393431296552189 and parameters: {'n_estimators': 135, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 18, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:56:16,497]\u001b[0m Trial 19 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 127, 'criterion': 'gini', 'max_depth': 6, 'n': 2, 'min_df': 18, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:56:37,786]\u001b[0m Trial 20 finished with value: 0.3929931583027198 and parameters: {'n_estimators': 103, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 12, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:57:09,087]\u001b[0m Trial 21 finished with value: 0.39346499949445585 and parameters: {'n_estimators': 159, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 22, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:57:40,369]\u001b[0m Trial 22 finished with value: 0.3930268612449867 and parameters: {'n_estimators': 167, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 17, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:58:07,715]\u001b[0m Trial 23 finished with value: 0.3931279700717873 and parameters: {'n_estimators': 137, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 21, 'sub_tf': 'True'}. Best is trial 7 with value: 0.4064237807960635.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:58:39,473]\u001b[0m Trial 24 finished with value: 0.4065417410939975 and parameters: {'n_estimators': 169, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 13, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:59:16,816]\u001b[0m Trial 25 finished with value: 0.39321222742745443 and parameters: {'n_estimators': 202, 'criterion': 'gini', 'max_depth': 6, 'n': 1, 'min_df': 13, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 13:59:45,897]\u001b[0m Trial 26 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 170, 'criterion': 'gini', 'max_depth': 5, 'n': 1, 'min_df': 5, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:00:29,538]\u001b[0m Trial 27 finished with value: 0.4063732263826632 and parameters: {'n_estimators': 202, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 10, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:01:18,607]\u001b[0m Trial 28 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 230, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 10, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:02:00,795]\u001b[0m Trial 29 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 226, 'criterion': 'entropy', 'max_depth': 5, 'n': 1, 'min_df': 7, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:02:42,871]\u001b[0m Trial 30 finished with value: 0.3930268612449867 and parameters: {'n_estimators': 194, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 13, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:03:19,456]\u001b[0m Trial 31 finished with value: 0.4064237807960635 and parameters: {'n_estimators': 168, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 10, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:03:57,025]\u001b[0m Trial 32 finished with value: 0.4064237807960635 and parameters: {'n_estimators': 174, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 10, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:04:35,072]\u001b[0m Trial 33 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 174, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 11, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:05:11,332]\u001b[0m Trial 34 finished with value: 0.40650803815173064 and parameters: {'n_estimators': 159, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 14, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:05:47,169]\u001b[0m Trial 35 finished with value: 0.40650803815173064 and parameters: {'n_estimators': 162, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 14, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:06:29,000]\u001b[0m Trial 36 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 149, 'criterion': 'entropy', 'max_depth': 5, 'n': 2, 'min_df': 15, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:06:56,643]\u001b[0m Trial 37 finished with value: 0.4065417410939975 and parameters: {'n_estimators': 119, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 14, 'sub_tf': 'True'}. Best is trial 24 with value: 0.4065417410939975.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:07:24,259]\u001b[0m Trial 38 finished with value: 0.4065754440362644 and parameters: {'n_estimators': 118, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 14, 'sub_tf': 'True'}. Best is trial 38 with value: 0.4065754440362644.\u001b[0m\n",
            "\u001b[32m[I 2021-07-20 14:07:47,773]\u001b[0m Trial 39 finished with value: 0.3929763068315864 and parameters: {'n_estimators': 117, 'criterion': 'entropy', 'max_depth': 4, 'n': 1, 'min_df': 16, 'sub_tf': 'True'}. Best is trial 38 with value: 0.4065754440362644.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyper-parameters: \n",
            "{'n_estimators': 118, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 14, 'sub_tf': 'True'}\n",
            "Best score: \n",
            "0.4065754440362644\n"
          ]
        }
      ],
      "source": [
        "class ForestModel:\n",
        "    def __init__(self, train_lemmatized, train_labels_list, valid_lemmatized, valid_labels_list):\n",
        "        self.train_lemmatized = train_lemmatized\n",
        "        self.train_labels_list = train_labels_list\n",
        "        self.valid_lemmatized = valid_lemmatized\n",
        "        self.valid_labels_list = valid_labels_list\n",
        "\n",
        "    def create_model(self, n_estimators, criterion, max_depth, n, min_df, sub_tf):\n",
        "        Forest_pipe = Pipeline([\n",
        "            ('vect', CountVectorizer(ngram_range = (1, n), min_df = min_df)),\n",
        "            ('tfidf', TfidfTransformer(sublinear_tf = sub_tf)),\n",
        "            ('classifier', RandomForestClassifier(\n",
        "                random_state = 3, n_estimators = n_estimators, criterion = criterion,\n",
        "                max_depth = max_depth ) )\n",
        "        ])\n",
        "        return Forest_pipe\n",
        "\n",
        "    def train_and_evaluate(self, trial):\n",
        "        # Sample values for the hyper-parameters\n",
        "        n_estimators = trial.suggest_int(\"n_estimators\", 100, 300)\n",
        "        criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
        "        max_depth = trial.suggest_int(\"max_depth\", 3, 6)\n",
        "        n = trial.suggest_int(\"n\", 1, 2)\n",
        "        min_df = trial.suggest_int(\"min_df\",5,25)\n",
        "        sub_tf = trial.suggest_categorical(\"sub_tf\", [\"True\",\"False\"])\n",
        "\n",
        "        # Create and fit model\n",
        "        clf_Forest = self.create_model(n_estimators, criterion, max_depth, n, min_df, sub_tf)\n",
        "        clf_Forest.fit(self.train_lemmatized, self.train_labels_list)\n",
        "\n",
        "        # Obtain the predictions and accuracy\n",
        "        predictions = clf_Forest.predict(self.valid_lemmatized)\n",
        "        acc = accuracy_score(self.valid_labels_list, predictions)\n",
        "\n",
        "        return acc\n",
        "\n",
        "    def optimize(self, budget):\n",
        "        # Select budget and set seed\n",
        "        np.random.seed(0)\n",
        "\n",
        "        # Optimize hyper-parameters\n",
        "        study_Forest = optuna.create_study(direction=\"maximize\")\n",
        "        study_Forest.optimize(lambda trial: self.train_and_evaluate(trial), n_trials=budget, show_progress_bar=False)\n",
        "\n",
        "        # Best hyper-parameters\n",
        "        print(\"Best hyper-parameters: \")\n",
        "        print(study_Forest.best_params)\n",
        "        # Best score\n",
        "        print(\"Best score: \")\n",
        "        print(study_Forest.best_value)\n",
        "\n",
        "# Initialize the model\n",
        "forest_model = ForestModel(train_lemmatized, train_labels_list, valid_lemmatized, valid_labels_list)\n",
        "\n",
        "# Optimize hyper-parameters\n",
        "forest_model.optimize(budget=40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoXpYs3WJPa_"
      },
      "source": [
        "## Model Evaluation\n",
        "\n",
        "### Stemming \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdh6dhHvJPbA"
      },
      "outputs": [],
      "source": [
        "# Join train and validation sets\n",
        "training_stemmed = train_stemmed + valid_stemmed\n",
        "training_lemmatized =  train_lemmatized + valid_lemmatized\n",
        "\n",
        "# Joining train and validation labels\n",
        "training_labels = train_labels_list + valid_labels_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWbeyAcTgjBf"
      },
      "source": [
        "#### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKv9k7QqJPbJ",
        "outputId": "f47c0b0d-5de8-4ead-9788-c0a96009fe98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.90      0.73     23507\n",
            "           1       0.84      0.10      0.17      3514\n",
            "           2       0.72      0.44      0.55     11297\n",
            "           3       0.91      0.01      0.02      1224\n",
            "           4       0.69      0.66      0.68     17472\n",
            "           5       0.92      0.33      0.48      2305\n",
            "\n",
            "    accuracy                           0.65     59319\n",
            "   macro avg       0.78      0.41      0.44     59319\n",
            "weighted avg       0.69      0.65      0.62     59319\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Best hyper-parameters\n",
        "#'n': 2, 'sub_tf': 'False', 'min_df': 5\n",
        "\n",
        "# Training\n",
        "Bayes_pipe = Pipeline([('vect', CountVectorizer(ngram_range = (1, 2), min_df = 5)),\n",
        "                            ('tfidf', TfidfTransformer(sublinear_tf = 'False')),('classifier', MultinomialNB() )])\n",
        "Bayes_pipe.fit(training_stemmed, training_labels)\n",
        "\n",
        "# Evaluation of the model\n",
        "predictions_Bayes_stem = Bayes_pipe.predict(test_stemmed)\n",
        "print(classification_report(np.array(test_labels_list).reshape(len(test_labels),1),predictions_Bayes_stem))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU5I2Bfx9fzo",
        "outputId": "8eef549b-5ed8-4196-f4ad-fdbafef97c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.84      0.10      0.17      3514\n",
            "           2       0.72      0.44      0.55     11297\n",
            "           3       0.91      0.01      0.02      1224\n",
            "           4       0.69      0.66      0.68     17472\n",
            "           5       0.92      0.33      0.48      2305\n",
            "\n",
            "   micro avg       0.71      0.49      0.58     35812\n",
            "   macro avg       0.82      0.31      0.38     35812\n",
            "weighted avg       0.74      0.49      0.55     35812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report without 0 label\n",
        "print(classification_report(np.array(test_labels).reshape(len(test_labels),1),predictions_Bayes_stem, labels = [1,2,3,4,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j150vIza9csp",
        "outputId": "da8d8fff-ea23-45b8-be7e-5589f2b87106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[21047    21   826     0  1605     8]\n",
            " [ 1927   334   213     0  1033     7]\n",
            " [ 4476    17  4994     0  1772    38]\n",
            " [  782     2    71    10   355     4]\n",
            " [ 5242    18   616     1 11584    11]\n",
            " [  979     6   230     0   334   756]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix\n",
        "print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1),predictions_Bayes_stem))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYI9y_n8h_Hp"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVk87dCKJPbJ",
        "outputId": "6e03830a-03f2-4210-d5fe-8a3a840ebf3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.86      0.79     23507\n",
            "           1       0.64      0.24      0.34      3514\n",
            "           2       0.69      0.54      0.60     11297\n",
            "           3       0.63      0.12      0.20      1224\n",
            "           4       0.73      0.81      0.77     17472\n",
            "           5       0.78      0.52      0.62      2305\n",
            "\n",
            "    accuracy                           0.72     59319\n",
            "   macro avg       0.70      0.51      0.55     59319\n",
            "weighted avg       0.71      0.72      0.70     59319\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Best hyper-parameters\n",
        "# 'max_iter': 373, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'\n",
        "\n",
        "# Training\n",
        "Logistic_pipe = Pipeline([('vect', CountVectorizer(ngram_range = (1, 2), min_df = 5)),\n",
        "                            ('tfidf', TfidfTransformer(sublinear_tf = 'True')),('classifier', LogisticRegression(random_state = 3,\n",
        "                                    solver = 'newton-cg', multi_class = 'multinomial',   max_iter = 373 ) )])\n",
        "Logistic_pipe.fit(training_stemmed, training_labels)\n",
        "\n",
        "# Evaluation of the model\n",
        "predictions_Logistic_stem = Logistic_pipe.predict(test_stemmed)\n",
        "print(classification_report(np.array(test_labels_list).reshape(len(test_labels),1),predictions_Logistic_stem))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_OvLYaT-ldZ",
        "outputId": "214dce97-a615-4625-ed47-0515ddb87f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.64      0.24      0.34      3514\n",
            "           2       0.69      0.54      0.60     11297\n",
            "           3       0.63      0.12      0.20      1224\n",
            "           4       0.73      0.81      0.77     17472\n",
            "           5       0.78      0.52      0.62      2305\n",
            "\n",
            "   micro avg       0.72      0.63      0.67     35812\n",
            "   macro avg       0.69      0.44      0.51     35812\n",
            "weighted avg       0.71      0.63      0.65     35812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report without 0 label\n",
        "print(classification_report(np.array(test_labels).reshape(len(test_labels),1),predictions_Logistic_stem, labels = [1,2,3,4,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RssiLutT-k9F",
        "outputId": "61a55f44-322c-44f1-a517-4c6824fd7356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[20236   164  1255    29  1696   127]\n",
            " [ 1238   827   272    12  1125    40]\n",
            " [ 3104    85  6072    22  1921    93]\n",
            " [  690    33   102   147   236    16]\n",
            " [ 2080   144   956    16 14222    54]\n",
            " [  634    47   180     6   248  1190]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix\n",
        "print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1),predictions_Logistic_stem))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS_ITrbyiims"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QdQHoWbJPbJ",
        "outputId": "772642c6-447e-4b21-fea8-1160079f1d72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      1.00      0.57     23507\n",
            "           1       0.00      0.00      0.00      3514\n",
            "           2       0.00      0.00      0.00     11297\n",
            "           3       0.00      0.00      0.00      1224\n",
            "           4       1.00      0.00      0.00     17472\n",
            "           5       0.00      0.00      0.00      2305\n",
            "\n",
            "    accuracy                           0.40     59319\n",
            "   macro avg       0.23      0.17      0.09     59319\n",
            "weighted avg       0.45      0.40      0.22     59319\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Best hyper-parameters\n",
        "# 'n_estimators': 142, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 24, 'sub_tf': 'True'\n",
        "\n",
        "# Training\n",
        "Forest_pipe = Pipeline([('vect', CountVectorizer(ngram_range = (1, 1), min_df = 24)),\n",
        "                            ('tfidf', TfidfTransformer(sublinear_tf = 'True')),('classifier', RandomForestClassifier(\n",
        "                                random_state = 3, n_estimators = 142, criterion = 'entropy',\n",
        "                                max_depth = 6) )])\n",
        "Forest_pipe.fit(training_stemmed, training_labels)\n",
        "\n",
        "# Evaluation of the model\n",
        "predictions_Forest_stem = Forest_pipe.predict(test_stemmed)\n",
        "print(classification_report(np.array(test_labels_list).reshape(len(test_labels),1),predictions_Forest_stem))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYEf7rEf-uYb",
        "outputId": "0b990838-5027-46d9-bf8f-3ad305672664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00      3514\n",
            "           2       0.00      0.00      0.00     11297\n",
            "           3       0.00      0.00      0.00      1224\n",
            "           4       1.00      0.00      0.00     17472\n",
            "           5       0.00      0.00      0.00      2305\n",
            "\n",
            "   micro avg       1.00      0.00      0.00     35812\n",
            "   macro avg       0.20      0.00      0.00     35812\n",
            "weighted avg       0.49      0.00      0.00     35812\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report without 0 label\n",
        "print(classification_report(np.array(test_labels).reshape(len(test_labels),1),predictions_Forest_stem, labels = [1,2,3,4,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yjlgHP1-uPB",
        "outputId": "007fc9d6-60fe-4952-f693-bd262ce2f620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[23507     0     0     0     0     0]\n",
            " [ 3514     0     0     0     0     0]\n",
            " [11297     0     0     0     0     0]\n",
            " [ 1224     0     0     0     0     0]\n",
            " [17471     0     0     0     1     0]\n",
            " [ 2305     0     0     0     0     0]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix\n",
        "print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1),predictions_Forest_stem))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6qlDTXLkBTo"
      },
      "source": [
        "### Lemmatization\n",
        "\n",
        "\n",
        "#### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq0ICK_rJPbJ",
        "outputId": "56ebb30c-7867-44bc-97f4-0196c0e4b70e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.90      0.73     23507\n",
            "           1       0.83      0.10      0.17      3514\n",
            "           2       0.72      0.44      0.55     11297\n",
            "           3       0.92      0.01      0.02      1224\n",
            "           4       0.70      0.66      0.68     17472\n",
            "           5       0.92      0.33      0.49      2305\n",
            "\n",
            "    accuracy                           0.65     59319\n",
            "   macro avg       0.78      0.41      0.44     59319\n",
            "weighted avg       0.69      0.65      0.62     59319\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Best hyper-parameters\n",
        "# 'n': 2, 'sub_tf': 'True', 'min_df': 5\n",
        "\n",
        "# Training\n",
        "Bayes_pipe_lem = Pipeline([('vect', CountVectorizer(ngram_range = (1, 2), min_df = 5)),\n",
        "                            ('tfidf', TfidfTransformer(sublinear_tf = 'True')),('classifier', MultinomialNB() )])\n",
        "Bayes_pipe_lem.fit(training_lemmatized, training_labels)\n",
        "\n",
        "# Evaluation of the model\n",
        "predictions_Bayes_lem = Bayes_pipe_lem.predict(test_lemmatized)\n",
        "print(classification_report(np.array(test_labels).reshape(len(test_labels),1),predictions_Bayes_lem))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id3xY-oH-92f",
        "outputId": "84c37403-40f8-49d4-b9a9-07cdf761428e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.10      0.17      3514\n",
            "           2       0.72      0.44      0.55     11297\n",
            "           3       0.92      0.01      0.02      1224\n",
            "           4       0.70      0.66      0.68     17472\n",
            "           5       0.92      0.33      0.49      2305\n",
            "\n",
            "   micro avg       0.71      0.49      0.58     35812\n",
            "   macro avg       0.82      0.31      0.38     35812\n",
            "weighted avg       0.74      0.49      0.55     35812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report without 0 label\n",
        "print(classification_report(np.array(test_labels).reshape(len(test_labels),1),predictions_Bayes_lem, labels = [1,2,3,4,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH0Rs59w--co",
        "outputId": "15059748-e42b-4688-abcd-efc482a4744f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[21055    21   817     0  1606     8]\n",
            " [ 1953   335   196     0  1025     5]\n",
            " [ 4470    19  5014     0  1759    35]\n",
            " [  786     3    71    12   348     4]\n",
            " [ 5238    22   614     1 11584    13]\n",
            " [  977     5   230     0   327   766]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix\n",
        "print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1),predictions_Bayes_lem))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvsTIPsxk-uy"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKYWMoRqgWs-",
        "outputId": "c2694361-4e9d-4c3b-daf9-274e86f4fc3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.86      0.79     23507\n",
            "           1       0.63      0.23      0.34      3514\n",
            "           2       0.69      0.54      0.60     11297\n",
            "           3       0.68      0.12      0.21      1224\n",
            "           4       0.73      0.81      0.77     17472\n",
            "           5       0.79      0.51      0.62      2305\n",
            "\n",
            "    accuracy                           0.72     59319\n",
            "   macro avg       0.71      0.51      0.55     59319\n",
            "weighted avg       0.71      0.72      0.70     59319\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Best hyper-parameters\n",
        "# 'max_iter': 390, 'solver': 'newton-cg', 'multi_class': 'multinomial', 'n': 2, 'min_df': 5, 'sub_tf': 'True'\n",
        "\n",
        "# Training\n",
        "Logistic_pipe_lem = Pipeline([('vect', CountVectorizer(ngram_range = (1, 2), min_df = 5)),\n",
        "                            ('tfidf', TfidfTransformer(sublinear_tf = 'True')),('classifier', LogisticRegression(random_state = 3,\n",
        "                                    solver = 'newton-cg', multi_class = 'multinomial',   max_iter = 390 ) )])\n",
        "Logistic_pipe_lem.fit(training_lemmatized, training_labels)\n",
        "\n",
        "# Evaluation of the model\n",
        "predictions_Logistic_lem = Logistic_pipe_lem.predict(test_lemmatized)\n",
        "print(classification_report(np.array(test_labels).reshape(len(test_labels),1),predictions_Logistic_lem))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaNlH_bl_KIH",
        "outputId": "bc89e734-6c42-4c9e-c08c-ebd8003939d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      0.23      0.34      3514\n",
            "           2       0.69      0.54      0.60     11297\n",
            "           3       0.68      0.12      0.21      1224\n",
            "           4       0.73      0.81      0.77     17472\n",
            "           5       0.79      0.51      0.62      2305\n",
            "\n",
            "   micro avg       0.72      0.63      0.67     35812\n",
            "   macro avg       0.70      0.44      0.51     35812\n",
            "weighted avg       0.71      0.63      0.65     35812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report without 0 label\n",
        "print(classification_report(np.array(test_labels).reshape(len(test_labels),1),predictions_Logistic_lem, labels = [1,2,3,4,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyYmCbcc_Kmx",
        "outputId": "0c45c76c-defc-40ed-b8c6-2715f83beb69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[20235   170  1252    27  1706   117]\n",
            " [ 1241   825   256     9  1149    34]\n",
            " [ 3116    82  6056    19  1932    92]\n",
            " [  682    32    99   150   245    16]\n",
            " [ 2111   153   953    10 14194    51]\n",
            " [  647    46   179     5   249  1179]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix\n",
        "print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1),predictions_Logistic_lem))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvKfUTktlr1i"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkZJMUyogWrC",
        "outputId": "4845abe2-d0c0-4889-90b3-9635590b9182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      1.00      0.57     23507\n",
            "           1       0.00      0.00      0.00      3514\n",
            "           2       0.00      0.00      0.00     11297\n",
            "           3       0.00      0.00      0.00      1224\n",
            "           4       1.00      0.04      0.08     17472\n",
            "           5       0.00      0.00      0.00      2305\n",
            "\n",
            "    accuracy                           0.41     59319\n",
            "   macro avg       0.23      0.17      0.11     59319\n",
            "weighted avg       0.45      0.41      0.25     59319\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Best hyper-parameters\n",
        "# 'n_estimators': 118, 'criterion': 'entropy', 'max_depth': 6, 'n': 1, 'min_df': 14, 'sub_tf': 'True'\n",
        "\n",
        "# Training\n",
        "Forest_pipe_lem = Pipeline([('vect', CountVectorizer(ngram_range = (1, 1), min_df = 14)),\n",
        "                            ('tfidf', TfidfTransformer(sublinear_tf = 'True')),('classifier', RandomForestClassifier(\n",
        "                                random_state = 3, n_estimators = 118, criterion = 'entropy',\n",
        "                                max_depth = 6) )])\n",
        "Forest_pipe_lem.fit(training_lemmatized, training_labels)\n",
        "\n",
        "# Evaluation of the model\n",
        "predictions_Forest_lem = Forest_pipe_lem.predict(test_lemmatized)\n",
        "print(classification_report(np.array(test_labels).reshape(len(test_labels),1),predictions_Forest_lem))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtbwSyJq_R3d",
        "outputId": "32349683-99e1-4c45-8568-5e37b2105f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00      3514\n",
            "           2       0.00      0.00      0.00     11297\n",
            "           3       0.00      0.00      0.00      1224\n",
            "           4       1.00      0.04      0.08     17472\n",
            "           5       0.00      0.00      0.00      2305\n",
            "\n",
            "   micro avg       1.00      0.02      0.04     35812\n",
            "   macro avg       0.20      0.01      0.02     35812\n",
            "weighted avg       0.49      0.02      0.04     35812\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Classification report without 0 label\n",
        "print(classification_report(np.array(test_labels).reshape(len(test_labels),1),predictions_Forest_lem, labels = [1,2,3,4,5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRBachv6_Se_",
        "outputId": "ee3b1070-002b-4356-afe2-703ec62f4d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[23507     0     0     0     0     0]\n",
            " [ 3514     0     0     0     0     0]\n",
            " [11297     0     0     0     0     0]\n",
            " [ 1224     0     0     0     0     0]\n",
            " [16743     0     0     0   729     0]\n",
            " [ 2305     0     0     0     0     0]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix\n",
        "print(confusion_matrix(np.array(test_labels).reshape(len(test_labels),1),predictions_Forest_lem))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Traditional_machine_learning_algorithms.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
